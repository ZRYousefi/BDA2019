---
title: "BDA - Assignment 8"
author: "Anonymous"
output: pdf_document
---

```{r setup, include=FALSE}
# This chunk just sets echo = TRUE as default (i.e. print all code)
knitr::opts_chunk$set(echo = TRUE)
```
```{r}

library(tidyr) 
library(rstan) 
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
library(loo)
library(ggplot2)
library(gridExtra)
library(bayesplot)
theme_set(bayesplot::theme_default(base_family = "sans"))
library(shinystan)
source('stan_utility.R')
library(aaltobda)
SEED <- 48927 # set random seed for reproducability
```


\textbf{Problem 1: Fit the models with Stan as instructed in Assignment 7. } 

## A) Separate model 
```{r}
data("factory")
```
First I considered the separated model. For this model, each machine j is assumed to have unrelated means $\mu_j$ and $\sigma_j$. The priors are also non-informative (uniform). The Stan implementation is as follows:
  
```{r}
writeLines(readLines("separat.stan"))
```
The data related to this model is : 
```{r}
data_separate <-list(N = ncol(factory) * nrow(factory),
                     K = ncol(factory),
                     x = rep(1:ncol(factory), nrow(factory)),
                     y = c(t(factory)))
```
We fit the separate model in stan as follow: 
```{r}  
fit_separate <- stan(file="separat.stan", data = data_separate, seed = SEED)
# monitor(fit_separate, probs = c(0.1, 0.5, 0.9))
```

## B) Pooled model 
For the pooled model I assumed that $\mu$ and $\sigma$ are the same for all machines. I also assumed uniform (non-informatice) priror for these parameters. The Stan implementation for pooled model is as:
  
```{r}
writeLines(readLines("pooled.stan"))
```
The data related to this model is : 
```{r}
data_pooled <- list(N = ncol(factory) * nrow(factory),
                    y = c(t(factory)))
```

We fit the pooled model in stan as follows: 
```{r}  
fit_pooled <- stan(file = "pooled.stan", data = data_pooled, seed = SEED)
```

## C) Hierarchical model 

In this model the means of the different machines are assumed to have a common standard deviation $\sigma$ and means $\mu$ that are drawn from a normal distribution with $\mu_0$ and $\sigma_0$. I assumed weekly informative priors for $\mu_0$ and $\sigma_0$ and $\sigma$. The
Stan implementation of the model is as follows:


```{r}
writeLines(readLines("hierarchical.stan"))
```

We fit the separate model in stan as follow: 
```{r}  
fit_hierarchical <- stan(file="hierarchical.stan", data = data_separate, seed = SEED)
```
\textbf{Problem 2: Compute the PSIS-LOO elpd values and the $\hat{k}$-values for each of the three models.}

The PSIS-LOO elpd and p\_loo values are computed using the following codes for each model. The $\hat{k}$-values are visualized in Problem 4 section to estimate the reliability of each model. 

```{r} 
log_lik_separate <- extract_log_lik(fit_separate, merge_chains = FALSE)
r_eff_separate <- relative_eff(exp(log_lik_separate)) 
loo_separate <- loo(log_lik_separate, r_eff = r_eff_separate)
print(loo_separate)
```




```{r} 
log_lik_pooled <- extract_log_lik(fit_pooled, merge_chains = FALSE)
r_eff_pooled <- relative_eff(exp(log_lik_pooled)) 
loo_pooled <- loo(log_lik_pooled, r_eff = r_eff_pooled)
print(loo_pooled)
```



```{r} 
log_lik_hierarchical <- extract_log_lik(fit_hierarchical, merge_chains = FALSE)
r_eff_hierarchical <- relative_eff(exp(log_lik_hierarchical)) 
loo_hierarchical <- loo(log_lik_hierarchical, r_eff = r_eff_hierarchical)
print(loo_hierarchical)

```


\textbf{Problem 3: Compute the effective number of parameters $p_{eff}$ for each of the three models.}

The effective number of parameters can be calculated usinf $p_{eff} = lpd - elpd_{loo}$ which is already calculated in loo() function as p\_loo. Therefore, $p_{eff}$ is approximately 9.5 , 2 and 5.6 for separate, pooled and hierarchical model, respectively. 



\textbf{Problem 4: Assess how reliable the PSIS-LOO estimates are for the three models based on the
$\hat{k}$-values.}

In order to assess the reliability of PSIS-LOO estimates, I plot the PSIS diagnostic plot for three models that shows the $\hat{k}$-values for each observation. Pareto $\hat{k}$ estimates the tail shape and determines the convergence rate of PSIS. If these values are less than 0.7 they would be ok and the model would be reliable. 
```{r} 
plot(loo_separate, diagnostic = c("k", "n_eff"),
  label_points = FALSE, main = "PSIS diagnostic plot: separate model")
```
```{r} 
plot(loo_pooled, diagnostic = c("k", "n_eff"),
  label_points = FALSE, main = "PSIS diagnostic plot: pooled model")
```
```{r} 
plot(loo_hierarchical, diagnostic = c("k", "n_eff"),
  label_points = FALSE, main = "PSIS diagnostic plot: hierarchical model")
```
As it can be seen from the plots, in the separate model there are two observations with pareto $\hat{k}$ values more than 0.7 which indicates that this model is not reliable. However, in the pooled model all the $\hat{k}$-values are less that or equal to 0.5 which means this model is reliable. In the hirerachical mdoel there are 3 $\hat{k}$-values which are $0.5<\hat{k}<0.7$ and 
therefore the hierachical model is also reliable. 

\textbf{Problem 5: An assessment of whether there are differences between the models with regard to
the elpd loo-cv , and if so, which model should be selected according to PSIS-LOO.}

We can now compare the models on LOO using the compare function. This object contains the estimated difference of expected leave-one-out prediction errors between the two models, along with the standard error:
```{r} 
compare_sep_pooled <- compare(loo_separate, loo_pooled)
print(compare_sep_pooled)
```

The positive difference in elpd (and its scale relative to the standard error) indicates a preference for the second model.


```{r} 
compare_sep_hier <- compare(loo_separate, loo_hierarchical)
print(compare_sep_hier)
```

```{r} 
compare_pooled_hier <- compare(loo_pooled, loo_hierarchical)
print(compare_pooled_hier)

```

According to the above comparisons, the hierarchical model is a clear winner in the predictive performance and its PSIS-LOO has the highest value among the three models.


